## GCP

Here‚Äôs a battle-tested setup that catches vendor quirks (like Cloud SQL tiers/editions) before you run apply.

‚∏ª

1) Add provider-specific linting (local + CI)

Use TFLint with the Google ruleset. It flags many GCP-specific gotchas that terraform validate can‚Äôt (wrong arguments, region/feature mismatches, etc.). Run it in pre-commit and CI:

.tflint.hcl

plugin "google" {
  enabled = true
  source  = "github.com/terraform-linters/tflint-ruleset-google"
  # pin for reproducibility; update on your schedule
  version = ">= 0.37.0"
}

# optional: adjust severities / enable extra rules
config {
  call_module_type = "all"
}

Then:

tflint --init
tflint --format compact

TFLint + the Google ruleset is well maintained and purpose-built for these checks.  Ôøº

‚∏ª

2) Fail fast with plan-time preconditions (Terraform ‚â•1.2)

Terraform lets you attach precondition checks to resources/data sources. They evaluate during plan, so you can block bad combos (e.g., ENTERPRISE_PLUS + db-n1-*).  Ôøº

For Cloud SQL, the Google provider exposes data.google_sql_tiers, which lists valid tiers for your project/region. Use it to assert your chosen tier is allowed for the current edition/region before apply:  Ôøº

# Fetch available tiers for the region/project
data "google_sql_tiers" "this" {
  project = var.project_id
  region  = var.region
}

# Example: ensure tier is valid and edition-compatible at plan-time
resource "google_sql_database_instance" "main" {
  name             = var.instance_name
  database_version = "POSTGRES_15"
  region           = var.region

  settings {
    edition = var.edition          # e.g., "ENTERPRISE_PLUS" or "ENTERPRISE"
    tier    = var.tier             # e.g., "db-perf-optimized-N-2" (‚úÖ) or "db-n1-standard-2" (‚ùå)
  }

  lifecycle {
    precondition {
      condition     = contains([for t in data.google_sql_tiers.this.tiers : t.tier], var.tier)
      error_message = "Tier ${var.tier} is not offered in ${var.region} for project ${var.project_id}."
    }
    precondition {
      condition = (
        (var.edition == "ENTERPRISE_PLUS" && can(regex("^db-perf-optimized-", var.tier))) ||
        (var.edition != "ENTERPRISE_PLUS")                                  # relax or add other patterns as needed
      )
      error_message = "Edition ${var.edition} requires a 'db-perf-optimized-*' tier. Update var.tier."
    }
  }
}

Tip: if a provider lacks a suitable data source, you can still validate with the external data source and a tiny script that shells out to a vendor CLI (e.g., gcloud sql tiers list --format=json) and returns JSON for your preconditions to check.  Ôøº

‚∏ª

3) Write tests for configurations (matrix your variables)

Terraform 1.6 introduced terraform test (.tftest.hcl). You can run speculative plans over a matrix of var combos and assert they pass your preconditions‚Äîno real apply needed. Great for catching edition/tier/region mismatches in CI.  Ôøº

example.tftest.hcl

run "enterprise_plus_requires_perf_optimized" {
  command = plan
  variables = {
    edition = "ENTERPRISE_PLUS"
    tier    = "db-n1-standard-2"
  }
  expect_failures = [
    resource.google_sql_database_instance.main
  ]
}

run "enterprise_plus_with_perf_optimized_ok" {
  command = plan
  variables = {
    edition = "ENTERPRISE_PLUS"
    tier    = "db-perf-optimized-N-2"
  }
}


‚∏ª

4) Keep a canary apply cheap and automated

Some API nuances only surface in a real apply. Automate a throwaway project (or folder with org-policy/budget limits) that runs a minimal end-to-end ‚Äúsmoke‚Äù apply/destroy on PRs or nightly:
	‚Ä¢	Separate GCP project with limited quotas/budget alerts.
	‚Ä¢	Tiny resources (or count = 0/1 behind a flag).
	‚Ä¢	terraform apply -auto-approve followed by terraform destroy if the plan succeeds.

This catches real provider API changes with minimal cost, without blocking day-to-day.

‚∏ª

5) Version discipline + proactive upgrades
	‚Ä¢	Pin required_providers and Terraform versions so behavior doesn‚Äôt change under your feet; periodically run a scheduled CI job that does terraform init -upgrade, tflint, and terraform test against the canary to detect breaking changes early.

‚∏ª

6) Quick wins you can drop in today
	‚Ä¢	Variable validation as a first line of defense:

variable "edition" {
  type = string
  validation {
    condition     = contains(["ENTERPRISE", "ENTERPRISE_PLUS"], var.edition)
    error_message = "Edition must be ENTERPRISE or ENTERPRISE_PLUS."
  }
}


	‚Ä¢	Pre-commit hooks: terraform_fmt, terraform_validate, tflint. (pre-commit-terraform has ready-made hooks.)
	‚Ä¢	Module guardrails: put the preconditions inside your shared module so every consumer benefits.

‚∏ª

Why this helps with your exact errors
	‚Ä¢	‚ÄúInvalid Tier (db-n1-standard-2) for (ENTERPRISE_PLUS)‚Ä¶ use db-perf-optimized-N-‚Äù*
‚Üí The precondition + regex("^db-perf-optimized-") check rejects this at plan time. data.google_sql_tiers guarantees the value actually exists in the region/project.  Ôøº
	‚Ä¢	‚ÄúOnly custom or shared-core instance Billing Tier type allowed for PostgreSQL‚Äù
‚Üí Encode an edition/database-version ‚Üí allowed tier patterns map and assert it in a precondition. If Google adjusts availability, refreshing data.google_sql_tiers will make the plan fail instead of the apply.

## AWS

Yes ‚Äî there is a dedicated ruleset for TFLint covering Terraform-AWS configurations: the plugin tflint‚Äëruleset‚Äëaws (hosted under terraform-linters/tflint-ruleset-aws).  Ôøº

‚úÖ What it covers
	‚Ä¢	The ruleset ‚Äúfocus[es] on possible errors and best practices about AWS resources‚Äù.  Ôøº
	‚Ä¢	Example: It catches something like you using an invalid instance_type for aws_instance, even though Terraform syntax is valid but the AWS API would reject it.  Ôøº
	‚Ä¢	Contains 700+ rules for AWS resources.  Ôøº
	‚Ä¢	You can configure it via your .tflint.hcl just as with other plugins.  Ôøº

‚ö† What it doesn‚Äôt do (or may not fully do)
	‚Ä¢	While it catches many provider-specific mismatches (like invalid properties, bad types, deprecated settings), it may not cover every single nuance of AWS API/edition/region-specific restrictions.
	‚Ä¢	For example, if AWS introduces a new restriction (e.g., a region stops allowing a particular machine type) you might still hit it at apply unless the ruleset has been updated to catch that.
	‚Ä¢	Custom or advanced policies (mappings of edition ‚Üí allowed tier, or cross-resource interplay) may still require custom rules or ‚Äúprecondition‚Äù style checks (as discussed earlier).
	‚Ä¢	Some rules may not be enabled by default, or may require explicit configuration to enforce.  Ôøº

üîß How to enable it in your project

Here‚Äôs a minimal .tflint.hcl snippet:

plugin "aws" {
  enabled = true
  version = "0.43.0"                  # pick a version you are comfortable with
  source  = "github.com/terraform-linters/tflint-ruleset-aws"
}

# Optionally you can disable specific rules you don‚Äôt want
rule "aws_instance_invalid_type" {
  enabled = true
}

Then run:

tflint --init
tflint --recursive

üéØ Recommended next step for you

Since you‚Äôre dealing with subtle ‚Äúapply-time only‚Äù failures (e.g., edition/tier mismatches), I‚Äôd suggest:
	1.	Enable tflint-ruleset-aws in your codebase (if you haven‚Äôt yet).
	2.	Browse the rules list and see if there are existing rules that catch the specific ‚Äúedition vs tier‚Äù combinations you hit. The repository has docs for each rule.  Ôøº
	3.	If no existing rule covers your exact nuance (say ‚Äúif edition = X then tier must match pattern Y‚Äù), you can write a custom rule or add a ‚Äúprecondition‚Äù in Terraform (as earlier discussed) for that check.
	4.	Integrate tflint into your CI/PR pipeline so these mismatches get caught before apply.
